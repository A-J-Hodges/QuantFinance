{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Quant Finance\n",
    "\n",
    "## Module 1.5: Bayesian inference\n",
    "\n",
    "### 1.5.3 Representing prior knowledge: postcodes\n",
    "\n",
    "In the last module we looked at incorporating prior knowledge into our models, but effectively cheated by saying \"all outcomes are just as likely, until we have data\". Often we have more information than that.\n",
    "\n",
    "In this module we look at how to take prior information about the domain we are investigating, and using that information to alter our model.\n",
    "\n",
    "\n",
    "- France's *La Poste* has used automated sorting since 1964.\n",
    "- Handwritten digit recognition has been well studied.\n",
    "- In order to use digit recognition in practice for sorting mail, we need a *prior* model for how probable each postcode is, independent of each actual digitized hand-written digit image in front of us.\n",
    "\n",
    "A sample of some Australian and international postcodes:\n",
    "- 2000 (Sydney)\n",
    "- 3122 (Hawthorn, VIC)\n",
    "- 4350 (used for 44 towns near Toowoomba, QLD)\n",
    "- 8007 (PO boxes in Collins Street West)\n",
    "- A-1220 (Vienna, Austria)\n",
    "- Tsuen Wan (Hong Kong): no postcodes in HK\n",
    "- 02138 (Cambridge, MA)\n",
    "- EC1V 4AD (London)\n",
    "\n",
    "\n",
    "### A prior for Australian postcodes\n",
    "\n",
    "**What prior information do we have?**\n",
    "\n",
    "- Do all Australian postcodes have 4 digits? Yes.\n",
    "- What range? 0200 to 9944\n",
    "- States:\n",
    "   - NSW: postcodes 1000-1999 (PO boxes), 2000-2599, 2620-2899, 2921-2999\n",
    "   - ACT: 0200-0299 (PO boxes), 2600-2619, 2900-2920\n",
    "   - VIC: 3000-3999, 8000-8999 (PO boxes)\n",
    "   - QLD: 4000-4999, 9000-9999 (PO boxes)\n",
    "   - SA: 5000-5799, 5800-5999 (PO boxes)\n",
    "   - WA 6000-6797, 6800-6999 (PO boxes)\n",
    "   - TAS: 7000-7799, 7800-7999 (PO boxes)\n",
    "   - NT: 0800-0899, 0900-0999 (PO boxes)\n",
    "\n",
    "**Also:**\n",
    "\n",
    "- 25% of all mail goes to these CBD postcodes: 2000, 2001, 3000, 3001, 4000, 4001, 5000, 5001, 6000, 6001.\n",
    "- We can look up population for each postcode. Or, if we don't have population info by postcode, we could seed the prior with state population data.\n",
    "- Within each state xxxx, 80% of mail goes to x0xx and x1xx (metropolitan city areas and suburbs).\n",
    "\n",
    "### How do we encode this prior information for machine learning purposes?\n",
    "\n",
    "### Goal: construct a prior $p(\\textrm{postcode})$ over all 4-digit postcodes\n",
    "\n",
    "### Valid ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "postcodes_by_state = dict((\n",
    "    ('Australian Capital Territory', set(range(2600, 2620)) | set(range(2900, 2920))),\n",
    "    ('New South Wales', set(range(2000, 3000)) - set(range(2600, 2620)) - set(range(2900, 2920))),\n",
    "    ('Victoria', set(range(3000, 4000))),\n",
    "    ('Queensland', set(range(4000, 5000))),\n",
    "    ('South Australia', set(range(5000, 5800))),\n",
    "    ('Western Australia', set(range(6000, 6798))),\n",
    "    ('Tasmania', set(range(7000, 7800))),\n",
    "    ('Northern Territory', set(range(800, 900)))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State populations\n",
    "\n",
    "We will start by using state populations as a proxy for really knowing the proportion of mail sent to each postcode.\n",
    "\n",
    "(If we obtain more data, we can update and improve our model by applying Bayes' theorem later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ../Data/aus_state_populations.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ab79470093b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstate_populations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/aus_state_populations.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/quant/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             raise compat.FileNotFoundError(\n\u001b[0;32m--> 371\u001b[0;31m                 'File %s does not exist' % path_or_buf)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File ../Data/aus_state_populations.h5 does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state_populations = pd.read_hdf('../Data/aus_state_populations.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [],
   "source": [
    "state_populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the desired feature expectations for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [],
   "source": [
    "# Source of the data:\n",
    "def fetch_state_populations():\n",
    "    url = 'http://www.ausstats.abs.gov.au/Ausstats/subscriber.nsf/0/D52DEAAFCEDF7B2ACA2580EB00133359/$File/31010do001_201609.xls'\n",
    "\n",
    "    state_pop = pd.read_excel(url, sheetname='Table_8', skiprows=6,\n",
    "                  names=['State', 'Population', '%'])\n",
    "\n",
    "    state_pop.set_index('State', inplace=True)\n",
    "\n",
    "    drop_row_idx = list(state_pop.index).index('Other Territories')\n",
    "\n",
    "    state_pop.drop(state_pop.index[drop_row_idx:], inplace=True)\n",
    "\n",
    "    state_pop['Population'] = state_pop['Population'].astype(int)\n",
    "    # state_pop.to_hdf('state_populations.h5', key='populations')\n",
    "    return state_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to incorporate this?\n",
    "\n",
    "... to model the probability of e.g. $p(\\textrm{postcode}=3122)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "def prior_state(state):\n",
    "    return state_populations['%'].loc[state] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    }
   },
   "outputs": [],
   "source": [
    "prior_state('New South Wales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a prior $p(\\text{state})$.\n",
    "\n",
    "### From the definition of conditional probability:\n",
    "\n",
    "$p(\\textrm{postcode}) = \\sum_{\\textrm{all states}} p(\\textrm{postcode | state}) p(\\textrm{state})$\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Assuming you have a function `prior_postcode_given_state(postcode, state)`, implement this as a function `prior_postcode(postcode)`.\n",
    "\n",
    "### Solution hint:\n",
    "\n",
    "Iterate over all states in `state_populations.index`.\n",
    "\n",
    "### Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [],
   "source": [
    "def prior_postcode(postcode):\n",
    "    p = 0.0\n",
    "    for state in state_populations.index:\n",
    "        p += prior_postcode_given_state(postcode, state) * prior_state(state)\n",
    "    assert p <= 1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "- Now write the function `prior_postcode_given_state(postcode, state)`.\n",
    "\n",
    "Assume you can assign equal probability to each valid postcode in the corresponding state (or 0 probability for the wrong state).\n",
    "\n",
    "### Then try out both your functions -- for example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> prior_postcode_given_state(3122, 'Victoria')\n",
    "\n",
    ">>> prior_postcode(3122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [],
   "source": [
    "def prior_postcode_given_state(postcode, state):\n",
    "    postcodes = postcodes_by_state[state]\n",
    "    return 1 / len(postcodes) if postcode in postcodes else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [],
   "source": [
    "prior_postcode_given_state(3122, 'Victoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    }
   },
   "outputs": [],
   "source": [
    "prior_postcode(3122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did we do?\n",
    "\n",
    "We informally constructed a prior model that was as **flat** (uninformative) as possible **subject to a constraint** that the proportion of mail being delivered to a postcode is equal to the state's population, divided by the number of postcodes for that state.\n",
    "\n",
    "### Consider now: how would you update the model to reflect that ...\n",
    "\n",
    "1. 25% of all mail goes to one of the CBD postcodes; and\n",
    "2. Within each state xxxx, 80% of mail goes to x0xx and x1xx (metropolitan city areas and suburbs)?\n",
    "\n",
    "### Maximum entropy models: the easy way\n",
    "\n",
    "Here we see how to derive such prior models in a more systematic and principled way using the `maxentropy` package.\n",
    "\n",
    "### Step 1: Set up the domain (or \"sample space\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "samplespace = np.arange(10000, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "17"
    }
   },
   "outputs": [],
   "source": [
    "samplespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up a list of feature functions whose expectations you want to constrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "18"
    }
   },
   "outputs": [],
   "source": [
    "def is_valid(postcodes):\n",
    "    return [200 <= postcode < 10000 for postcode in postcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    }
   },
   "outputs": [],
   "source": [
    "# def in_nsw(postcodes):\n",
    "#     return [postcode in postcodes_by_state['New South Wales'] for postcode in postcodes]\n",
    "# etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "20"
    }
   },
   "outputs": [],
   "source": [
    "def in_given_state(state):\n",
    "    def in_state(postcodes):\n",
    "        return [postcode in postcodes_by_state[state] for postcode in postcodes]\n",
    "    return in_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "21"
    }
   },
   "outputs": [],
   "source": [
    "state_populations.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "22"
    }
   },
   "outputs": [],
   "source": [
    "features = [is_valid] + \\\n",
    "           [in_given_state(state) for state in state_populations.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "23"
    }
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: create a `MinDivergenceModel` object from this list of features and sample space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install maxentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "25"
    }
   },
   "outputs": [],
   "source": [
    "from maxentropy.skmaxent import MinDivergenceModel\n",
    "\n",
    "model = MinDivergenceModel(features, samplespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: define your desired array of expected feature function values (one for each feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "26"
    }
   },
   "outputs": [],
   "source": [
    "pop = state_populations['%'] / 100\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "27"
    }
   },
   "outputs": [],
   "source": [
    "state_populations['%'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This excludes the other territories, like Norfolk Island. Ignore this for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "28"
    }
   },
   "outputs": [],
   "source": [
    "k = np.r_[0.999, pop.values].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "29"
    }
   },
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "30"
    }
   },
   "outputs": [],
   "source": [
    "len(features) == k.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: fit your model under those constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "31"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "32"
    }
   },
   "outputs": [],
   "source": [
    "model.expectations() - k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "33"
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(model.expectations(), k, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: our fitted prior model is given by `model.probdist()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "34"
    }
   },
   "outputs": [],
   "source": [
    "model.probdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "36"
    }
   },
   "outputs": [],
   "source": [
    "assert len(model.probdist() == len(samplespace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a prior probability $\\textrm{prior}(\\textrm{postcode})$ for each 4-digit postcode.\n",
    "\n",
    "### What are the most probable postcodes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "37"
    }
   },
   "outputs": [],
   "source": [
    "p = model.probdist()\n",
    "np.argsort(p)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "38"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "39"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(12, 5))\n",
    "plt.plot(samplespace, p, '.', )\n",
    "axes.set_xlabel('postcode')\n",
    "axes.set_ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise incorporating more prior knowledge\n",
    "\n",
    "Now try to incorporate the additional prior knowledge that 40% of all mail\n",
    "goes to the following CBD postcodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "40"
    }
   },
   "outputs": [],
   "source": [
    "CBD_POSTCODES = {2000, 2001, 3000, 3001, 4000, 4001, 5000, 5001, 6000, 6001}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution hint:\n",
    "1. Define a new feature function `in_cbd(postcode)` and append this to your list of features.\n",
    "2. Add an additional value (0.4) to your array of constraint values of feature expectations.\n",
    "3. Re-create your model passing in your new features.\n",
    "4. Re-fit your model passing in the new constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "41"
    }
   },
   "outputs": [],
   "source": [
    "def in_cbd(postcodes):\n",
    "    return [postcode in CBD_POSTCODES for postcode in postcodes]\n",
    "\n",
    "features2 = features + [in_cbd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "42"
    }
   },
   "outputs": [],
   "source": [
    "k2 = np.c_[k, 0.25]\n",
    "k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "43"
    }
   },
   "outputs": [],
   "source": [
    "assert len(features2) == k2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "44"
    }
   },
   "outputs": [],
   "source": [
    "model2 = MinDivergenceModel(features2, samplespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "45"
    }
   },
   "outputs": [],
   "source": [
    "model2.fit(k2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "54"
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(model2.expectations(), k2, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "46"
    }
   },
   "outputs": [],
   "source": [
    "p2 = model2.probdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "47"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(12, 5))\n",
    "plt.plot(samplespace, p2, '.', )\n",
    "axes.set_xlabel('postcode')\n",
    "axes.set_ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see more by using a logarithmic vertical axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "48"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(12, 5))\n",
    "plt.semilogy(samplespace, p2, '.', )\n",
    "axes.set_xlabel('postcode')\n",
    "axes.set_ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More prior knowledge: CBD, inner suburbs, outer suburbs, regional centres\n",
    "\n",
    "Here is an example of how to incorporate this extra information:\n",
    "\n",
    "- Within each state xxxx, 80% of mail goes to x0xx and x1xx (metropolitan city areas and suburbs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "56"
    }
   },
   "outputs": [],
   "source": [
    "def which_ring(postcodes):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    0 if postcode is x0xx\n",
    "    100 if postcode is x1xx\n",
    "    200 if postcode is x2xx\n",
    "    ... otherwise\n",
    "    \"\"\"\n",
    "    return [postcode % 1000 - postcode % 100 for postcode in postcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "57"
    }
   },
   "outputs": [],
   "source": [
    "which_ring([1234, 800, 2900, 3000, 2001, 2099, 3122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "58"
    }
   },
   "outputs": [],
   "source": [
    "def in_city_metropolitan_area(postcodes):\n",
    "    return [ring == 0 or ring == 100 for ring in which_ring(postcodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "59"
    }
   },
   "outputs": [],
   "source": [
    "in_city_metropolitan_area([3136, 3122, 2001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "60"
    }
   },
   "outputs": [],
   "source": [
    "features3 = features2 + [in_city_metropolitan_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "61"
    }
   },
   "outputs": [],
   "source": [
    "k3 = np.c_[k2, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "62"
    }
   },
   "outputs": [],
   "source": [
    "model3 = MinDivergenceModel(features3, samplespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "63"
    }
   },
   "outputs": [],
   "source": [
    "model3.fit(k3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "64"
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(model3.expectations(), k3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "65"
    }
   },
   "outputs": [],
   "source": [
    "p3 = model3.probdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "66"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(12, 5))\n",
    "plt.semilogy(samplespace, p3, '.', )\n",
    "axes.set_xlabel('postcode')\n",
    "axes.set_ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This prior reflects **precisely** the information we put into the model.\n",
    "\n",
    "No less:\n",
    "- all constraints we placed on it are satisfied;\n",
    "\n",
    "No more:\n",
    "- no additional information is reflected / assumed which we didn't explicitly add. It is as flat as possible (maximal entropy) subject to our constraints.\n",
    "\n",
    "### Next notebook: we will fuse this prior information with data for a better model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "67"
    }
   },
   "outputs": [],
   "source": [
    "np.save('postcode_prior3.npy', p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Demonstration that we cannot tweak `model` to be equivalent to `model2` by adding one constraint (`in_cbd`) and then minimizing KL divergence from `model1`.\n",
    "\n",
    "Let's try it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "125"
    }
   },
   "outputs": [],
   "source": [
    "model4 = MinDivergenceModel([in_cbd], samplespace, model.log_probdist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "126"
    }
   },
   "outputs": [],
   "source": [
    "k4 = np.array([0.25], ndmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "129"
    }
   },
   "outputs": [],
   "source": [
    "model4.fit(k4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "130"
    }
   },
   "outputs": [],
   "source": [
    "model4.expectations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "131"
    }
   },
   "outputs": [],
   "source": [
    "p4 = model4.probdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "132"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(12, 5))\n",
    "plt.semilogy(samplespace, p4, '.', )\n",
    "axes.set_xlabel('postcode')\n",
    "axes.set_ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is different because the process is different. We are no longer asserting the same constraints as before -- we are only asserting one single constraint. So this will in general have higher entropy (be flatter) than the more constrained model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}